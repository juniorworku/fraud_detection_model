{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/106076302893227074', creation_time=1718905080887, experiment_id='106076302893227074', last_update_time=1718905080887, lifecycle_stage='active', name='MLflow Quickstart', tags={}>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Set our tracking server uri for logging\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")\n",
    "\n",
    "# Create a new MLflow Experiment\n",
    "mlflow.set_experiment(\"MLflow Quickstart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "fraud_data = pd.read_csv('../data/raw/Fraud_Data.csv')\n",
    "ip_data = pd.read_csv('../data/raw/IpAddress_to_Country.csv')\n",
    "creditcard_data = pd.read_csv('../data/raw/creditcard.csv')\n",
    "\n",
    "# Convert datetime strings to datetime objects\n",
    "fraud_data['signup_time'] = pd.to_datetime(fraud_data['signup_time'])\n",
    "fraud_data['purchase_time'] = pd.to_datetime(fraud_data['purchase_time'])\n",
    "\n",
    "# Extract useful datetime components\n",
    "fraud_data['signup_hour'] = fraud_data['signup_time'].dt.hour\n",
    "fraud_data['signup_day'] = fraud_data['signup_time'].dt.dayofweek\n",
    "fraud_data['purchase_hour'] = fraud_data['purchase_time'].dt.hour\n",
    "fraud_data['purchase_day'] = fraud_data['purchase_time'].dt.dayofweek\n",
    "\n",
    "# Drop the original datetime columns\n",
    "fraud_data = fraud_data.drop(columns=['signup_time', 'purchase_time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For fraud_data\n",
    "fraud_X = fraud_data.drop(columns=['class'])\n",
    "fraud_y = fraud_data['class']\n",
    "# For creditcard_data\n",
    "creditcard_X = creditcard_data.drop(columns=['Class'])\n",
    "creditcard_y = creditcard_data['Class']\n",
    "\n",
    "# Split fraud_data\n",
    "fraud_X_train, fraud_X_test, fraud_y_train, fraud_y_test = train_test_split(fraud_X, fraud_y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split creditcard_data\n",
    "creditcard_X_train, creditcard_X_test, creditcard_y_train, creditcard_y_test = train_test_split(creditcard_X, creditcard_y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing for numerical and categorical features\n",
    "numeric_features = ['purchase_value', 'age']  # Example numeric features\n",
    "categorical_features = ['source', 'browser', 'sex', 'signup_hour', 'signup_day', 'purchase_hour', 'purchase_day']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Selection\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'MLP': MLPClassifier()\n",
    "}\n",
    "\n",
    "# Function to train and evaluate models for fraud data\n",
    "def train_evaluate_model_fraud(model_name, model, X_train, X_test, y_train, y_test):\n",
    "    # Create a pipeline with preprocessing and model\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('classifier', model)])\n",
    "\n",
    "    # Train the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    # Infer model signature\n",
    "    signature = infer_signature(X_train, y_pred)\n",
    "\n",
    "    # Log metrics and model with MLflow\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        mlflow.log_param(\"model\", model_name)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.set_tag(\"Training Info\", \"All models for Fraud detection\")\n",
    "        model_info = mlflow.sklearn.log_model(\n",
    "            sk_model=pipeline,\n",
    "            artifact_path=\"fraud_model\",\n",
    "            signature=signature,\n",
    "            input_example=X_train,\n",
    "            registered_model_name=f\"{model_name}_fraud_detection\",\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1\n",
    "    }\n",
    "\n",
    "# Function to train and evaluate models for credit card data\n",
    "def train_evaluate_model_credit(model_name, model, X_train, X_test, y_train, y_test):\n",
    "    # Create a pipeline with preprocessing and model\n",
    "    pipeline = Pipeline(steps=[('classifier', model)])\n",
    "\n",
    "    # Train the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    # Infer model signature\n",
    "    signature = infer_signature(X_train, y_pred)\n",
    "\n",
    "    # Log metrics and model with MLflow\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        mlflow.log_param(\"model\", model_name)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.set_tag(\"Training Info\", \"All models for Credit Card Fraud detection\")\n",
    "        model_info = mlflow.sklearn.log_model(\n",
    "            sk_model=pipeline,\n",
    "            artifact_path=\"creditcard_model\",\n",
    "            signature=signature,\n",
    "            input_example=X_train,\n",
    "            registered_model_name=f\"{model_name}_creditcard_detection\",\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ted\\Desktop\\Juju\\DEV\\fraud_detection_model\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Ted\\Desktop\\Juju\\DEV\\fraud_detection_model\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Successfully registered model 'Logistic Regression_fraud_detection'.\n",
      "2024/06/20 21:07:20 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Logistic Regression_fraud_detection, version 1\n",
      "Created version '1' of model 'Logistic Regression_fraud_detection'.\n",
      "c:\\Users\\Ted\\Desktop\\Juju\\DEV\\fraud_detection_model\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Successfully registered model 'Decision Tree_fraud_detection'.\n",
      "2024/06/20 22:01:35 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Decision Tree_fraud_detection, version 1\n",
      "Created version '1' of model 'Decision Tree_fraud_detection'.\n",
      "c:\\Users\\Ted\\Desktop\\Juju\\DEV\\fraud_detection_model\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Successfully registered model 'Random Forest_fraud_detection'.\n",
      "2024/06/20 23:33:32 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Random Forest_fraud_detection, version 1\n",
      "Created version '1' of model 'Random Forest_fraud_detection'.\n",
      "c:\\Users\\Ted\\Desktop\\Juju\\DEV\\fraud_detection_model\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Successfully registered model 'Gradient Boosting_fraud_detection'.\n",
      "2024/06/21 00:02:06 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Gradient Boosting_fraud_detection, version 1\n",
      "Created version '1' of model 'Gradient Boosting_fraud_detection'.\n",
      "c:\\Users\\Ted\\Desktop\\Juju\\DEV\\fraud_detection_model\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Ted\\Desktop\\Juju\\DEV\\fraud_detection_model\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Successfully registered model 'MLP_fraud_detection'.\n",
      "2024/06/21 00:29:07 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: MLP_fraud_detection, version 1\n",
      "Created version '1' of model 'MLP_fraud_detection'.\n",
      "c:\\Users\\Ted\\Desktop\\Juju\\DEV\\fraud_detection_model\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Successfully registered model 'Logistic Regression_creditcard_detection'.\n",
      "2024/06/21 00:29:31 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Logistic Regression_creditcard_detection, version 1\n",
      "Created version '1' of model 'Logistic Regression_creditcard_detection'.\n",
      "Successfully registered model 'Decision Tree_creditcard_detection'.\n",
      "2024/06/21 00:30:11 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Decision Tree_creditcard_detection, version 1\n",
      "Created version '1' of model 'Decision Tree_creditcard_detection'.\n",
      "Successfully registered model 'Random Forest_creditcard_detection'.\n",
      "2024/06/21 00:33:59 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Random Forest_creditcard_detection, version 1\n",
      "Created version '1' of model 'Random Forest_creditcard_detection'.\n",
      "Successfully registered model 'Gradient Boosting_creditcard_detection'.\n",
      "2024/06/21 00:39:46 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Gradient Boosting_creditcard_detection, version 1\n",
      "Created version '1' of model 'Gradient Boosting_creditcard_detection'.\n",
      "Successfully registered model 'MLP_creditcard_detection'.\n",
      "2024/06/21 00:40:23 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: MLP_creditcard_detection, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud Data Results:\n",
      "                  model  accuracy  precision    recall  f1_score\n",
      "0  Logistic Regression  0.906979   0.000000  0.000000  0.000000\n",
      "1        Decision Tree  0.908987   0.509699  0.566991  0.536821\n",
      "2        Random Forest  0.957052   0.993050  0.542092  0.701335\n",
      "3    Gradient Boosting  0.908457   0.935065  0.017074  0.033535\n",
      "4                  MLP  0.948185   0.839884  0.547309  0.662742\n",
      "Credit Card Data Results:\n",
      "                  model  accuracy  precision    recall  f1_score\n",
      "0  Logistic Regression  0.998666   0.577465  0.602941  0.589928\n",
      "1        Decision Tree  0.999169   0.707006  0.816176  0.757679\n",
      "2        Random Forest  0.999602   0.939655  0.801471  0.865079\n",
      "3    Gradient Boosting  0.998584   0.894737  0.125000  0.219355\n",
      "4                  MLP  0.995904   0.257919  0.838235  0.394464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'MLP_creditcard_detection'.\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate models on fraud data\n",
    "fraud_results = []\n",
    "for model_name, model in models.items():\n",
    "    fraud_results.append(train_evaluate_model_fraud(model_name, model, fraud_X_train, fraud_X_test, fraud_y_train, fraud_y_test))\n",
    "\n",
    "# Train and evaluate models on credit card data\n",
    "creditcard_results = []\n",
    "for model_name, model in models.items():\n",
    "    creditcard_results.append(train_evaluate_model_credit(model_name, model, creditcard_X_train, creditcard_X_test, creditcard_y_train, creditcard_y_test))\n",
    "\n",
    "# Display results\n",
    "fraud_results_df = pd.DataFrame(fraud_results)\n",
    "creditcard_results_df = pd.DataFrame(creditcard_results)\n",
    "\n",
    "print(\"Fraud Data Results:\\n\", fraud_results_df)\n",
    "print(\"Credit Card Data Results:\\n\", creditcard_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6485ebe1389e4116a4e5882024729fd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      " [0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Load a model for inference\n",
    "logged_model = 'runs:/79c1280bbcc3459c8f2584cf2d14219d/fraud_model'\n",
    "\n",
    "# Load model as a PyFuncModel\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "# Use the loaded model to make predictions\n",
    "sample_input = fraud_X_test.iloc[:5]\n",
    "predictions = loaded_model.predict(sample_input)\n",
    "print(\"Predictions:\\n\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3804c3a9cb1c4e6e89c5249b7b926f25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "805e1399488f4d77aea4003e4e414f06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd27aca463d74889a11aca9a5e38edf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f7b5805bb04c789662a512cf70c45b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d713855c8874dd4a82e189d0731d42b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for fraud_model_79c1280bbcc3459c8f2584cf2d14219d:\n",
      "         Model                            Run ID  Index  Prediction\n",
      "0  fraud_model  79c1280bbcc3459c8f2584cf2d14219d      0           0\n",
      "1  fraud_model  79c1280bbcc3459c8f2584cf2d14219d      1           0\n",
      "2  fraud_model  79c1280bbcc3459c8f2584cf2d14219d      2           0\n",
      "3  fraud_model  79c1280bbcc3459c8f2584cf2d14219d      3           0\n",
      "4  fraud_model  79c1280bbcc3459c8f2584cf2d14219d      4           0\n",
      "\n",
      "Predictions for fraud_model_3548a18afe3e4b038e16d5f989adaa38:\n",
      "         Model                            Run ID  Index  Prediction\n",
      "0  fraud_model  3548a18afe3e4b038e16d5f989adaa38      0           0\n",
      "1  fraud_model  3548a18afe3e4b038e16d5f989adaa38      1           0\n",
      "2  fraud_model  3548a18afe3e4b038e16d5f989adaa38      2           0\n",
      "3  fraud_model  3548a18afe3e4b038e16d5f989adaa38      3           0\n",
      "4  fraud_model  3548a18afe3e4b038e16d5f989adaa38      4           0\n",
      "\n",
      "Predictions for fraud_model_1d316e8924224d38abaf5b4d39bdfb86:\n",
      "         Model                            Run ID  Index  Prediction\n",
      "0  fraud_model  1d316e8924224d38abaf5b4d39bdfb86      0           0\n",
      "1  fraud_model  1d316e8924224d38abaf5b4d39bdfb86      1           0\n",
      "2  fraud_model  1d316e8924224d38abaf5b4d39bdfb86      2           0\n",
      "3  fraud_model  1d316e8924224d38abaf5b4d39bdfb86      3           0\n",
      "4  fraud_model  1d316e8924224d38abaf5b4d39bdfb86      4           0\n",
      "\n",
      "Predictions for fraud_model_539c77b3762941818b8ec46320d9ae8c:\n",
      "         Model                            Run ID  Index  Prediction\n",
      "0  fraud_model  539c77b3762941818b8ec46320d9ae8c      0           0\n",
      "1  fraud_model  539c77b3762941818b8ec46320d9ae8c      1           0\n",
      "2  fraud_model  539c77b3762941818b8ec46320d9ae8c      2           0\n",
      "3  fraud_model  539c77b3762941818b8ec46320d9ae8c      3           0\n",
      "4  fraud_model  539c77b3762941818b8ec46320d9ae8c      4           0\n",
      "\n",
      "Predictions for fraud_model_2886dc3a43a845b4acaa4c1b84662cf9:\n",
      "         Model                            Run ID  Index  Prediction\n",
      "0  fraud_model  2886dc3a43a845b4acaa4c1b84662cf9      0           0\n",
      "1  fraud_model  2886dc3a43a845b4acaa4c1b84662cf9      1           0\n",
      "2  fraud_model  2886dc3a43a845b4acaa4c1b84662cf9      2           0\n",
      "3  fraud_model  2886dc3a43a845b4acaa4c1b84662cf9      3           0\n",
      "4  fraud_model  2886dc3a43a845b4acaa4c1b84662cf9      4           0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Making Prediction by using the loaded model for Fraud data\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "models_runs = [\n",
    "    ('fraud_model', '79c1280bbcc3459c8f2584cf2d14219d'),\n",
    "    ('fraud_model', '3548a18afe3e4b038e16d5f989adaa38'),\n",
    "    ('fraud_model', '1d316e8924224d38abaf5b4d39bdfb86'),\n",
    "    ('fraud_model', '539c77b3762941818b8ec46320d9ae8c'),\n",
    "    ('fraud_model', '2886dc3a43a845b4acaa4c1b84662cf9')\n",
    "]\n",
    "sample_input = fraud_X_test.iloc[:5]\n",
    "\n",
    "results_dfs = {}\n",
    "\n",
    "for model_name, run_id in models_runs:\n",
    "    logged_model = f'runs:/{run_id}/{model_name}'\n",
    "    \n",
    "    # Load the model as a PyFuncModel\n",
    "    loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = loaded_model.predict(sample_input)\n",
    "\n",
    "    # Create a DataFrame for the predictions\n",
    "    results_df = pd.DataFrame({\n",
    "        'Model': model_name,\n",
    "        'Run ID': run_id,\n",
    "        'Index': range(len(predictions)),\n",
    "        'Prediction': predictions\n",
    "    })\n",
    "    \n",
    "    # Store the DataFrame in the dictionary\n",
    "    results_dfs[f\"{model_name}_{run_id}\"] = results_df\n",
    "    \n",
    "# Display each DataFrame\n",
    "for key, df in results_dfs.items():\n",
    "    print(f\"Predictions for {key}:\\n{df}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "models_runs = [\n",
    "    ('fraud_model', '79c1280bbcc3459c8f2584cf2d14219d'),\n",
    "    ('fraud_model', '3548a18afe3e4b038e16d5f989adaa38'),\n",
    "    ('fraud_model', '1d316e8924224d38abaf5b4d39bdfb86'),\n",
    "    ('fraud_model', '539c77b3762941818b8ec46320d9ae8c'),\n",
    "    ('fraud_model', '2886dc3a43a845b4acaa4c1b84662cf9'),\n",
    "    ('creditcard_model', 'e791f0b0d76849ca9c142fb6651140e2'),\n",
    "    ('creditcard_model', '903c9fddc6ba425ba10e393e5b172282'),\n",
    "    ('creditcard_model', '5ab4536b36814340bcce64d2db6fb5aa'),\n",
    "    ('creditcard_model', '5c46165fea0d41999184d09b35498264'),\n",
    "    ('creditcard_model', 'bf46d67943534f2f8d196db97499b71b')\n",
    "]\n",
    "\n",
    "sample_input = fraud_X_test.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b768c447b704ddba13fdffbfb34d509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "579bf5a0beab4e998fded466cdc5a5f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a130d764bfd849b3b9b91daead90606b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc25c20780549cda6f1a591ef54508e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa14a8074044c1d95660f58c621165a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for creditcard_model_e791f0b0d76849ca9c142fb6651140e2:\n",
      "              Model                            Run ID  Index  Prediction\n",
      "0  creditcard_model  e791f0b0d76849ca9c142fb6651140e2      0           1\n",
      "1  creditcard_model  e791f0b0d76849ca9c142fb6651140e2      1           0\n",
      "2  creditcard_model  e791f0b0d76849ca9c142fb6651140e2      2           0\n",
      "3  creditcard_model  e791f0b0d76849ca9c142fb6651140e2      3           0\n",
      "4  creditcard_model  e791f0b0d76849ca9c142fb6651140e2      4           0\n",
      "\n",
      "Predictions for creditcard_model_903c9fddc6ba425ba10e393e5b172282:\n",
      "              Model                            Run ID  Index  Prediction\n",
      "0  creditcard_model  903c9fddc6ba425ba10e393e5b172282      0           1\n",
      "1  creditcard_model  903c9fddc6ba425ba10e393e5b172282      1           0\n",
      "2  creditcard_model  903c9fddc6ba425ba10e393e5b172282      2           0\n",
      "3  creditcard_model  903c9fddc6ba425ba10e393e5b172282      3           0\n",
      "4  creditcard_model  903c9fddc6ba425ba10e393e5b172282      4           0\n",
      "\n",
      "Predictions for creditcard_model_5ab4536b36814340bcce64d2db6fb5aa:\n",
      "              Model                            Run ID  Index  Prediction\n",
      "0  creditcard_model  5ab4536b36814340bcce64d2db6fb5aa      0           1\n",
      "1  creditcard_model  5ab4536b36814340bcce64d2db6fb5aa      1           0\n",
      "2  creditcard_model  5ab4536b36814340bcce64d2db6fb5aa      2           0\n",
      "3  creditcard_model  5ab4536b36814340bcce64d2db6fb5aa      3           0\n",
      "4  creditcard_model  5ab4536b36814340bcce64d2db6fb5aa      4           0\n",
      "\n",
      "Predictions for creditcard_model_5c46165fea0d41999184d09b35498264:\n",
      "              Model                            Run ID  Index  Prediction\n",
      "0  creditcard_model  5c46165fea0d41999184d09b35498264      0           0\n",
      "1  creditcard_model  5c46165fea0d41999184d09b35498264      1           0\n",
      "2  creditcard_model  5c46165fea0d41999184d09b35498264      2           0\n",
      "3  creditcard_model  5c46165fea0d41999184d09b35498264      3           0\n",
      "4  creditcard_model  5c46165fea0d41999184d09b35498264      4           0\n",
      "\n",
      "Predictions for creditcard_model_bf46d67943534f2f8d196db97499b71b:\n",
      "              Model                            Run ID  Index  Prediction\n",
      "0  creditcard_model  bf46d67943534f2f8d196db97499b71b      0           1\n",
      "1  creditcard_model  bf46d67943534f2f8d196db97499b71b      1           0\n",
      "2  creditcard_model  bf46d67943534f2f8d196db97499b71b      2           0\n",
      "3  creditcard_model  bf46d67943534f2f8d196db97499b71b      3           0\n",
      "4  creditcard_model  bf46d67943534f2f8d196db97499b71b      4           0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Making Prediction by using the loaded model for Credit card data\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "models_runs = [\n",
    "    ('creditcard_model', 'e791f0b0d76849ca9c142fb6651140e2'),\n",
    "    ('creditcard_model', '903c9fddc6ba425ba10e393e5b172282'),\n",
    "    ('creditcard_model', '5ab4536b36814340bcce64d2db6fb5aa'),\n",
    "    ('creditcard_model', '5c46165fea0d41999184d09b35498264'),\n",
    "    ('creditcard_model', 'bf46d67943534f2f8d196db97499b71b')\n",
    "]\n",
    "sample_input = creditcard_X_test.iloc[:5]\n",
    "\n",
    "results_dfs = {}\n",
    "\n",
    "for model_name, run_id in models_runs:\n",
    "    logged_model = f'runs:/{run_id}/{model_name}'\n",
    "    \n",
    "    # Load the model as a PyFuncModel\n",
    "    loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = loaded_model.predict(sample_input)\n",
    "\n",
    "    # Create a DataFrame for the predictions\n",
    "    results_df = pd.DataFrame({\n",
    "        'Model': model_name,\n",
    "        'Run ID': run_id,\n",
    "        'Index': range(len(predictions)),\n",
    "        'Prediction': predictions\n",
    "    })\n",
    "    \n",
    "    # Store the DataFrame in the dictionary\n",
    "    results_dfs[f\"{model_name}_{run_id}\"] = results_df\n",
    "    \n",
    "# Display each DataFrame\n",
    "for key, df in results_dfs.items():\n",
    "    print(f\"Predictions for {key}:\\n{df}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
