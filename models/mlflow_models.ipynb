{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "from data_processing import DataProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/22 09:20:27 INFO mlflow.tracking.fluent: Experiment with name 'MLflow for Fraud detection' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/410426737290025736', creation_time=1719037227525, experiment_id='410426737290025736', last_update_time=1719037227525, lifecycle_stage='active', name='MLflow for Fraud detection', tags={}>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Set our tracking server uri for logging\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")\n",
    "\n",
    "# Create a new MLflow Experiment\n",
    "mlflow.set_experiment(\"MLflow for Fraud detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "fraud_data_processor = DataProcessing('../data/raw/Fraud_Data.csv')\n",
    "fraud_data = fraud_data_processor.preprocess_data()\n",
    "\n",
    "ip_data_processor = DataProcessing('../data/raw/IpAddress_to_Country.csv')\n",
    "ip_data = ip_data_processor.preprocess_data()\n",
    "\n",
    "creditcard_data_processor = DataProcessing('../data/raw/creditcard.csv')\n",
    "creditcard_data = creditcard_data_processor.preprocess_data()\n",
    "\n",
    "\n",
    "# Convert datetime strings to datetime objects\n",
    "fraud_data['signup_time'] = pd.to_datetime(fraud_data['signup_time'])\n",
    "fraud_data['purchase_time'] = pd.to_datetime(fraud_data['purchase_time'])\n",
    "\n",
    "# Extract useful datetime components\n",
    "fraud_data['signup_hour'] = fraud_data['signup_time'].dt.hour\n",
    "fraud_data['signup_day'] = fraud_data['signup_time'].dt.dayofweek\n",
    "fraud_data['purchase_hour'] = fraud_data['purchase_time'].dt.hour\n",
    "fraud_data['purchase_day'] = fraud_data['purchase_time'].dt.dayofweek\n",
    "\n",
    "# Drop the original datetime columns\n",
    "fraud_data = fraud_data.drop(columns=['signup_time', 'purchase_time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For fraud_data\n",
    "fraud_X = fraud_data.drop(columns=['class'])\n",
    "fraud_y = fraud_data['class']\n",
    "# For creditcard_data\n",
    "creditcard_X = creditcard_data.drop(columns=['Class'])\n",
    "creditcard_y = creditcard_data['Class']\n",
    "\n",
    "# Split fraud_data\n",
    "fraud_X_train, fraud_X_test, fraud_y_train, fraud_y_test = train_test_split(fraud_X, fraud_y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split creditcard_data\n",
    "creditcard_X_train, creditcard_X_test, creditcard_y_train, creditcard_y_test = train_test_split(creditcard_X, creditcard_y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing for numerical and categorical features\n",
    "numeric_features = ['purchase_value', 'age']  # Example numeric features\n",
    "categorical_features = ['source', 'browser', 'sex', 'signup_hour', 'signup_day', 'purchase_hour', 'purchase_day']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Selection\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'MLP': MLPClassifier()\n",
    "}\n",
    "\n",
    "# Function to train and evaluate models for fraud data\n",
    "def train_evaluate_model_fraud(model_name, model, X_train, X_test, y_train, y_test):\n",
    "    # Create a pipeline with preprocessing and model\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('classifier', model)])\n",
    "\n",
    "    # Train the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    # Infer model signature\n",
    "    signature = infer_signature(X_train, y_pred)\n",
    "\n",
    "    # Log metrics and model with MLflow\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        mlflow.log_param(\"model\", model_name)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.set_tag(\"Training Info\", \"All models for Fraud detection\")\n",
    "        model_info = mlflow.sklearn.log_model(\n",
    "            sk_model=pipeline,\n",
    "            artifact_path=\"fraud_model\",\n",
    "            signature=signature,\n",
    "            input_example=X_train,\n",
    "            registered_model_name=f\"{model_name}_fraud_detection\",\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1\n",
    "    }\n",
    "\n",
    "# Function to train and evaluate models for credit card data\n",
    "def train_evaluate_model_credit(model_name, model, X_train, X_test, y_train, y_test):\n",
    "    # Create a pipeline with preprocessing and model\n",
    "    pipeline = Pipeline(steps=[('classifier', model)])\n",
    "\n",
    "    # Train the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    # Infer model signature\n",
    "    signature = infer_signature(X_train, y_pred)\n",
    "\n",
    "    # Log metrics and model with MLflow\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        mlflow.log_param(\"model\", model_name)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.set_tag(\"Training Info\", \"All models for Credit Card Fraud detection\")\n",
    "        model_info = mlflow.sklearn.log_model(\n",
    "            sk_model=pipeline,\n",
    "            artifact_path=\"creditcard_model\",\n",
    "            signature=signature,\n",
    "            input_example=X_train,\n",
    "            registered_model_name=f\"{model_name}_creditcard_detection\",\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ted\\Desktop\\Juju\\DEV\\fraud_detection_model\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Ted\\Desktop\\Juju\\DEV\\fraud_detection_model\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Registered model 'Logistic Regression_fraud_detection' already exists. Creating a new version of this model...\n",
      "2024/06/22 09:21:17 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Logistic Regression_fraud_detection, version 2\n",
      "Created version '2' of model 'Logistic Regression_fraud_detection'.\n",
      "c:\\Users\\Ted\\Desktop\\Juju\\DEV\\fraud_detection_model\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Registered model 'Decision Tree_fraud_detection' already exists. Creating a new version of this model...\n",
      "2024/06/22 09:21:40 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Decision Tree_fraud_detection, version 2\n",
      "Created version '2' of model 'Decision Tree_fraud_detection'.\n",
      "c:\\Users\\Ted\\Desktop\\Juju\\DEV\\fraud_detection_model\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Registered model 'Random Forest_fraud_detection' already exists. Creating a new version of this model...\n",
      "2024/06/22 09:24:28 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Random Forest_fraud_detection, version 2\n",
      "Created version '2' of model 'Random Forest_fraud_detection'.\n",
      "c:\\Users\\Ted\\Desktop\\Juju\\DEV\\fraud_detection_model\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Registered model 'Gradient Boosting_fraud_detection' already exists. Creating a new version of this model...\n",
      "2024/06/22 09:24:57 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Gradient Boosting_fraud_detection, version 2\n",
      "Created version '2' of model 'Gradient Boosting_fraud_detection'.\n",
      "c:\\Users\\Ted\\Desktop\\Juju\\DEV\\fraud_detection_model\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Ted\\Desktop\\Juju\\DEV\\fraud_detection_model\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Registered model 'MLP_fraud_detection' already exists. Creating a new version of this model...\n",
      "2024/06/22 09:27:11 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: MLP_fraud_detection, version 2\n",
      "Created version '2' of model 'MLP_fraud_detection'.\n",
      "c:\\Users\\Ted\\Desktop\\Juju\\DEV\\fraud_detection_model\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Registered model 'Logistic Regression_creditcard_detection' already exists. Creating a new version of this model...\n",
      "2024/06/22 09:27:37 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Logistic Regression_creditcard_detection, version 2\n",
      "Created version '2' of model 'Logistic Regression_creditcard_detection'.\n",
      "Successfully registered model 'Decision Tree_creditcard_detection'.\n",
      "2024/06/22 09:28:19 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Decision Tree_creditcard_detection, version 1\n",
      "Created version '1' of model 'Decision Tree_creditcard_detection'.\n",
      "Successfully registered model 'Random Forest_creditcard_detection'.\n",
      "2024/06/22 09:32:46 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Random Forest_creditcard_detection, version 1\n",
      "Created version '1' of model 'Random Forest_creditcard_detection'.\n",
      "Successfully registered model 'Gradient Boosting_creditcard_detection'.\n",
      "2024/06/22 09:39:46 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Gradient Boosting_creditcard_detection, version 1\n",
      "Created version '1' of model 'Gradient Boosting_creditcard_detection'.\n",
      "Successfully registered model 'MLP_creditcard_detection'.\n",
      "2024/06/22 09:40:48 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: MLP_creditcard_detection, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud Data Results:\n",
      "                  model  accuracy  precision    recall  f1_score\n",
      "0  Logistic Regression  0.906979   0.000000  0.000000  0.000000\n",
      "1        Decision Tree  0.909119   0.510299  0.569836  0.538427\n",
      "2        Random Forest  0.957140   0.995209  0.541854  0.701674\n",
      "3    Gradient Boosting  0.908457   0.935065  0.017074  0.033535\n",
      "4                  MLP  0.943663   0.779872  0.549443  0.644686\n",
      "Credit Card Data Results:\n",
      "                  model  accuracy  precision    recall  f1_score\n",
      "0  Logistic Regression  0.998666   0.577465  0.602941  0.589928\n",
      "1        Decision Tree  0.999204   0.732877  0.786765  0.758865\n",
      "2        Random Forest  0.999602   0.932203  0.808824  0.866142\n",
      "3    Gradient Boosting  0.998584   0.894737  0.125000  0.219355\n",
      "4                  MLP  0.998432   0.625000  0.036765  0.069444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'MLP_creditcard_detection'.\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate models on fraud data\n",
    "fraud_results = []\n",
    "for model_name, model in models.items():\n",
    "    fraud_results.append(train_evaluate_model_fraud(model_name, model, fraud_X_train, fraud_X_test, fraud_y_train, fraud_y_test))\n",
    "\n",
    "# Train and evaluate models on credit card data\n",
    "creditcard_results = []\n",
    "for model_name, model in models.items():\n",
    "    creditcard_results.append(train_evaluate_model_credit(model_name, model, creditcard_X_train, creditcard_X_test, creditcard_y_train, creditcard_y_test))\n",
    "\n",
    "# Display results\n",
    "fraud_results_df = pd.DataFrame(fraud_results)\n",
    "creditcard_results_df = pd.DataFrame(creditcard_results)\n",
    "\n",
    "print(\"Fraud Data Results:\\n\", fraud_results_df)\n",
    "print(\"Credit Card Data Results:\\n\", creditcard_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d0ead1f6b7442a59f847097d139e7ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      " [0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Load a model for inference\n",
    "logged_model = 'runs:/48369d081c0c46bcad19a91f6bbabbbd/fraud_model'\n",
    "\n",
    "# Load model as a PyFuncModel\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "# Use the loaded model to make predictions\n",
    "sample_input = fraud_X_test.iloc[:5]\n",
    "predictions = loaded_model.predict(sample_input)\n",
    "print(\"Predictions:\\n\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf92d66e52841cea37469f752e4c091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ab480ac7694eef847138f003f0d02f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6b0f6f9176845d4b65b8d31ff4ec7f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6f8ff1a4ec84b4f98eb17ef3bd032cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab8e2ff064c49b4a81e10cb3f995215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for fraud_model_48369d081c0c46bcad19a91f6bbabbbd:\n",
      "         Model                            Run ID  Index  Prediction\n",
      "0  fraud_model  48369d081c0c46bcad19a91f6bbabbbd      0           0\n",
      "1  fraud_model  48369d081c0c46bcad19a91f6bbabbbd      1           0\n",
      "2  fraud_model  48369d081c0c46bcad19a91f6bbabbbd      2           0\n",
      "3  fraud_model  48369d081c0c46bcad19a91f6bbabbbd      3           0\n",
      "4  fraud_model  48369d081c0c46bcad19a91f6bbabbbd      4           0\n",
      "\n",
      "Predictions for fraud_model_72bc2c38fb3a49969ee33116b5e00a84:\n",
      "         Model                            Run ID  Index  Prediction\n",
      "0  fraud_model  72bc2c38fb3a49969ee33116b5e00a84      0           0\n",
      "1  fraud_model  72bc2c38fb3a49969ee33116b5e00a84      1           0\n",
      "2  fraud_model  72bc2c38fb3a49969ee33116b5e00a84      2           0\n",
      "3  fraud_model  72bc2c38fb3a49969ee33116b5e00a84      3           0\n",
      "4  fraud_model  72bc2c38fb3a49969ee33116b5e00a84      4           0\n",
      "\n",
      "Predictions for fraud_model_8f48e744470244b5864b6bf373540bd7:\n",
      "         Model                            Run ID  Index  Prediction\n",
      "0  fraud_model  8f48e744470244b5864b6bf373540bd7      0           0\n",
      "1  fraud_model  8f48e744470244b5864b6bf373540bd7      1           0\n",
      "2  fraud_model  8f48e744470244b5864b6bf373540bd7      2           0\n",
      "3  fraud_model  8f48e744470244b5864b6bf373540bd7      3           0\n",
      "4  fraud_model  8f48e744470244b5864b6bf373540bd7      4           0\n",
      "\n",
      "Predictions for fraud_model_f5a0279ac66d44ffa206aef96fbbb74c:\n",
      "         Model                            Run ID  Index  Prediction\n",
      "0  fraud_model  f5a0279ac66d44ffa206aef96fbbb74c      0           0\n",
      "1  fraud_model  f5a0279ac66d44ffa206aef96fbbb74c      1           0\n",
      "2  fraud_model  f5a0279ac66d44ffa206aef96fbbb74c      2           0\n",
      "3  fraud_model  f5a0279ac66d44ffa206aef96fbbb74c      3           0\n",
      "4  fraud_model  f5a0279ac66d44ffa206aef96fbbb74c      4           0\n",
      "\n",
      "Predictions for fraud_model_7b35a9c50fca4ade979c654d35f784d7:\n",
      "         Model                            Run ID  Index  Prediction\n",
      "0  fraud_model  7b35a9c50fca4ade979c654d35f784d7      0           0\n",
      "1  fraud_model  7b35a9c50fca4ade979c654d35f784d7      1           0\n",
      "2  fraud_model  7b35a9c50fca4ade979c654d35f784d7      2           0\n",
      "3  fraud_model  7b35a9c50fca4ade979c654d35f784d7      3           0\n",
      "4  fraud_model  7b35a9c50fca4ade979c654d35f784d7      4           0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Making Prediction by using the loaded model for Fraud data\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "models_runs = [\n",
    "    ('fraud_model', '48369d081c0c46bcad19a91f6bbabbbd'),\n",
    "    ('fraud_model', '72bc2c38fb3a49969ee33116b5e00a84'),\n",
    "    ('fraud_model', '8f48e744470244b5864b6bf373540bd7'),\n",
    "    ('fraud_model', 'f5a0279ac66d44ffa206aef96fbbb74c'),\n",
    "    ('fraud_model', '7b35a9c50fca4ade979c654d35f784d7')\n",
    "]\n",
    "sample_input = fraud_X_test.iloc[:5]\n",
    "\n",
    "results_dfs = {}\n",
    "\n",
    "for model_name, run_id in models_runs:\n",
    "    logged_model = f'runs:/{run_id}/{model_name}'\n",
    "    \n",
    "    # Load the model as a PyFuncModel\n",
    "    loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = loaded_model.predict(sample_input)\n",
    "\n",
    "    # Create a DataFrame for the predictions\n",
    "    results_df = pd.DataFrame({\n",
    "        'Model': model_name,\n",
    "        'Run ID': run_id,\n",
    "        'Index': range(len(predictions)),\n",
    "        'Prediction': predictions\n",
    "    })\n",
    "    \n",
    "    # Store the DataFrame in the dictionary\n",
    "    results_dfs[f\"{model_name}_{run_id}\"] = results_df\n",
    "    \n",
    "# Display each DataFrame\n",
    "for key, df in results_dfs.items():\n",
    "    print(f\"Predictions for {key}:\\n{df}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7879d81dbaf4bf5ae9a883b5d67418f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f32075a76c7a4f14a4c06bba10f05882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc1fdf4069954b7488496b83ef9659f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35ff910941da485493a5357869114d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c44ea641fef438598451752ea3aff94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for creditcard_model_a4f2a14a3a9741e993ff861892ed210d:\n",
      "              Model                            Run ID  Index  Prediction\n",
      "0  creditcard_model  a4f2a14a3a9741e993ff861892ed210d      0           1\n",
      "1  creditcard_model  a4f2a14a3a9741e993ff861892ed210d      1           0\n",
      "2  creditcard_model  a4f2a14a3a9741e993ff861892ed210d      2           0\n",
      "3  creditcard_model  a4f2a14a3a9741e993ff861892ed210d      3           0\n",
      "4  creditcard_model  a4f2a14a3a9741e993ff861892ed210d      4           0\n",
      "\n",
      "Predictions for creditcard_model_6aed1e8ba5d648359b95a9586fff8053:\n",
      "              Model                            Run ID  Index  Prediction\n",
      "0  creditcard_model  6aed1e8ba5d648359b95a9586fff8053      0           1\n",
      "1  creditcard_model  6aed1e8ba5d648359b95a9586fff8053      1           0\n",
      "2  creditcard_model  6aed1e8ba5d648359b95a9586fff8053      2           0\n",
      "3  creditcard_model  6aed1e8ba5d648359b95a9586fff8053      3           0\n",
      "4  creditcard_model  6aed1e8ba5d648359b95a9586fff8053      4           0\n",
      "\n",
      "Predictions for creditcard_model_5aaec3c223f64856b6afa0cd52305551:\n",
      "              Model                            Run ID  Index  Prediction\n",
      "0  creditcard_model  5aaec3c223f64856b6afa0cd52305551      0           1\n",
      "1  creditcard_model  5aaec3c223f64856b6afa0cd52305551      1           0\n",
      "2  creditcard_model  5aaec3c223f64856b6afa0cd52305551      2           0\n",
      "3  creditcard_model  5aaec3c223f64856b6afa0cd52305551      3           0\n",
      "4  creditcard_model  5aaec3c223f64856b6afa0cd52305551      4           0\n",
      "\n",
      "Predictions for creditcard_model_344bc4ef2cf24ad49e923e56eb68b796:\n",
      "              Model                            Run ID  Index  Prediction\n",
      "0  creditcard_model  344bc4ef2cf24ad49e923e56eb68b796      0           0\n",
      "1  creditcard_model  344bc4ef2cf24ad49e923e56eb68b796      1           0\n",
      "2  creditcard_model  344bc4ef2cf24ad49e923e56eb68b796      2           0\n",
      "3  creditcard_model  344bc4ef2cf24ad49e923e56eb68b796      3           0\n",
      "4  creditcard_model  344bc4ef2cf24ad49e923e56eb68b796      4           0\n",
      "\n",
      "Predictions for creditcard_model_8ace3b2744db4d6cb597278d90f717c8:\n",
      "              Model                            Run ID  Index  Prediction\n",
      "0  creditcard_model  8ace3b2744db4d6cb597278d90f717c8      0           0\n",
      "1  creditcard_model  8ace3b2744db4d6cb597278d90f717c8      1           0\n",
      "2  creditcard_model  8ace3b2744db4d6cb597278d90f717c8      2           0\n",
      "3  creditcard_model  8ace3b2744db4d6cb597278d90f717c8      3           0\n",
      "4  creditcard_model  8ace3b2744db4d6cb597278d90f717c8      4           0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Making Prediction by using the loaded model for Credit card data\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "models_runs = [\n",
    "    ('creditcard_model', 'a4f2a14a3a9741e993ff861892ed210d'),\n",
    "    ('creditcard_model', '6aed1e8ba5d648359b95a9586fff8053'),\n",
    "    ('creditcard_model', '5aaec3c223f64856b6afa0cd52305551'),\n",
    "    ('creditcard_model', '344bc4ef2cf24ad49e923e56eb68b796'),\n",
    "    ('creditcard_model', '8ace3b2744db4d6cb597278d90f717c8')\n",
    "]\n",
    "sample_input = creditcard_X_test.iloc[:5]\n",
    "\n",
    "results_dfs = {}\n",
    "\n",
    "for model_name, run_id in models_runs:\n",
    "    logged_model = f'runs:/{run_id}/{model_name}'\n",
    "    \n",
    "    # Load the model as a PyFuncModel\n",
    "    loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = loaded_model.predict(sample_input)\n",
    "\n",
    "    # Create a DataFrame for the predictions\n",
    "    results_df = pd.DataFrame({\n",
    "        'Model': model_name,\n",
    "        'Run ID': run_id,\n",
    "        'Index': range(len(predictions)),\n",
    "        'Prediction': predictions\n",
    "    })\n",
    "    \n",
    "    # Store the DataFrame in the dictionary\n",
    "    results_dfs[f\"{model_name}_{run_id}\"] = results_df\n",
    "    \n",
    "# Display each DataFrame\n",
    "for key, df in results_dfs.items():\n",
    "    print(f\"Predictions for {key}:\\n{df}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
